{
    "model_type": "llama",

    "model_dir":  "/data1/wjh/projects/llama/llama-2-7b/llama_7b_ppl/",
    "model_param_path": "/data1/wjh/projects/llama/llama-2-7b/llama_7b_ppl/params.json",

    "tokenizer_path": "/data1/wjh/projects/llama/tokenizer.model",

    "tensor_parallel_size": 1,

    "top_p": 0.0,
    "top_k": 1,

    "quant_method": "none",

    "max_tokens_scale": 0.94,
    "max_tokens_per_request": 4096,
    "max_running_batch": 1024,
    "max_tokens_per_step": 8192,

    "host": "0.0.0.0",
    "port": 23333
}
